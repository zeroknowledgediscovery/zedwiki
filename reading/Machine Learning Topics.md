# ![ID](https://img.shields.io/badge/1--red) Machine Learning & Data Science

## Performance Measures

## Reciever Operating Characteristics

## Confusion Matrix

---

# ![ID](https://img.shields.io/badge/1--red) Probability Theory 

<img src='../uploads/dice.jpeg' width=100px>

## Random variables

## Bayes' Theorem

---

# ![ID](https://img.shields.io/badge/2--red) Bayesian Statsitics



## Baye's Error

## Bayes' Classifier

---


# ![ID](https://img.shields.io/badge/3--red) Bias vs Variance


## Optimal Model Complexity



---

# ![ID](https://img.shields.io/badge/4--red) The Scikit-learn Library

---


# ![ID](https://img.shields.io/badge/5--red) Classification 


## Naive Bayes
* A supervised learning algorithm
# Applies Bayesâ€™ Theorem using a naive assumption - assumes conditional independence between each pair of features (given value of the class variable)
* Used to classify data based on features 
* For example, classifying emails as spam or not spam



## Nearest Neighbor
* Unsupervised nearest neighbors - manifold learning and spectral clustering 
* Supervised neighbors - classification of data with discrete labels, and regression of data with continuous labels
* Works by finding the closest predefined number of training samples to a new point, and then predicting a label based on those 

### Brute force

* Only computes the distances between all pairs of points
* Classifies new data exclusively through these computed distances 

### KD tree

* Generates a binary tree structure through the recursive partitioning of data along the data axes provided
* Computes distances based on the partitions made by the tree as opposed to computing it for each data point, thus reducing the number of distance calculations

### Ball tree 

* KD Trees only partition data within cartesian axes, so ball trees separate data into a series of nesting hyper-spheres to all for higher dimensions
* The data is divided into nodes defined by a centroid and radius, and the neighbor search utilizes the triangle inequality for classification


## Support Vector Machines

* A supervised learning algorithm that can be used for classification, regression, and outlier detection
* Effective in high dimensions
* SVMs transform data (as necessary) into higher dimensions in order to best classify it based on the training data provided
* This is done through kernel functions that determine the relationships between data points and then set parameters to classify data


## Multi Layer Perceptron

## Random Forest

## AdaBoost

## Stochastic Gradient Descent

---


# ![ID](https://img.shields.io/badge/6--red) Regression

## LASSO

## Ridge

## LOESS

---

# ![ID](https://img.shields.io/badge/7--red) Embedding

---

# ![ID](https://img.shields.io/badge/8--red) Neural Networks

## Feed forward Networks

## Tensorflow Scripting

## Convolutional Neural Networks

---

# ![ID](https://img.shields.io/badge/9--red) Time Series Analysis

## ARIMA Models

## GARCH Models

## PFSA Models

---


# ![ID](https://img.shields.io/badge/10--red) Time Series Modeling with Neural Networks

## Recurrent Neural Networks

## Long-short Memory Models

---

# ![ID](https://img.shields.io/badge/11--red) Autoencoders

## Variational Autoencoders

## Autoencoders and Kolmogorov Complexity

---


# ![ID](https://img.shields.io/badge/12--red) Case Studies


## Comparison of Genomic Sequences

## Genome Wide Association Studies

## Epidemiology